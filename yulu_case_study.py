# -*- coding: utf-8 -*-
"""Yulu Case_Study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j6u13KkkteOBbczHUTtn_EnvIStvkB-f

# <font color='red'>1.	Define the Problem Statement, Import the required Libraries and perform Exploratory Data Analysis.</font>
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv("/content/bike_sharing.csv")

data.head()

data.shape

data.info()

data.isna().sum()

data.describe()

data[data.duplicated()].count()

"""**Observation:**
*	The dataframe has 1088 rows and 12 columns.
*	The datatype of the column datetime is object, and the columns tem, atemp, and widspeed have datatypes float.
*	The remaining columns have datatypes int.
*	There are no missing or duplicate values in the dataframe.

<font color='blue'>**Numerical & Categorical variables**:</font>
"""

data.nunique()

"""The columns season and weather each have 4 unique values, while the columns holiday and working days each have 2 unique values. These   columns will be treated as categorical variables, and the remaining columns will be treated as numerical columns.

1.Numerical Variables:
"""

# Temperature:

data["temp"].describe()

plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
sns.histplot(data["temp"])

plt.subplot(1,2,2)
sns.boxplot(data["temp"])

plt.suptitle("Distribution of Temperature Data", color="red")
plt.show()

"""* Temperatue data have approx normal distribution. data does not have outliers.
* The mean temperature is 20 degrees Celsius. The minimum temperature is 0.82 degrees Celsius, and the maximum temperature is 41 degrees Celsius.
* The 25th percentile of the data is 13.94 degrees Celsius.
* The 75th percentile of the data is 26.24 degrees Celsius.
"""

# atemp: temperature feel like

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["atemp"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["atemp"])
plt.suptitle("Distribution of atemp Data", color="red")
plt.show()

"""* The plot shows that 'atemp' does not follow a normal distribution, and it does not have outliers.
* The mean temperature is 23.65 degrees Celsius.
* The minimum temperature is 0.76 degrees Celsius, and the maximum temperature is 45.45 degrees Celsius.
* The 25th percentile of the data is 16.66 degrees Celsius.
* The 75th percentile of the data is 31 degrees Celsius.
"""



# Humidity
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["humidity"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["humidity"])
plt.suptitle("Distribution of Humidity Data", color="red")
plt.show()

"""* We can observe that the data is left-skewed, indicating that it has few values lower than the lower limit.
* The mean value is 61.88.
* The minimum value is 0, and the maximum value is 100.
* The first quartile (Q1) value is 47, and the third quartile (Q3) value is 77.
"""

# Windspeed

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["windspeed"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["windspeed"])

Q1= data["windspeed"].quantile(0.25)
Q3= data["windspeed"].quantile(0.75)
IQR= Q3-Q1
lower_limit= Q1 - 1.5*IQR
upper_limit= Q3 + 1.5*IQR

data[data["windspeed"]>upper_limit]["windspeed"].count()

"""* We can observe that the data is right-skewed and contains outliers. Specifically, the column 'windspeed' has 227 outliers.
* The mean value is 12.8.
"""

# Casual Users
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["casual"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["casual"])
plt.suptitle("Distribution of Casual bike rides", color="red")
plt.show()

Q1= data["casual"].quantile(0.25)
Q3= data["casual"].quantile(0.75)
IQR= Q3-Q1

lower_limit= Q1 - 1.5*IQR
upper_limit= Q3 + 1.5*IQR

data[data["casual"]>upper_limit]["casual"].count()

"""* Upon observing the data, it is evident that the data is right-skewed and contains outliers.
* There are 749 outliers where the values exceed the upper limit.
* The mean value is 36.
* The minimum value is 0, and the maximum value is 376.
"""

# Registered Users

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["registered"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["registered"])
plt.suptitle("Distribution of Registered bike rides", color="red")
plt.show()

Q1= data["registered"].quantile(0.25)
Q3= data["registered"].quantile(0.75)
IQR= Q3-Q1

lower_limit= Q1 - 1.5*IQR
upper_limit= Q3 + 1.5*IQR

data[data["registered"]>upper_limit]["registered"].count()

data["registered"].describe()

"""* Upon observing the data, it is evident that the data is right-skewed and contains outliers.
* There are 423 outliers where the values exceed the upper limit.
* The mean value is 155.
* The minimum value is 0, and the maximum value is 886.
"""

# Total Count
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.histplot(data["count"], kde=True)

plt.subplot(1,2,2)
sns.boxplot(data["count"])
plt.suptitle("Distribution of Total bike rides", color="red")
plt.show()

Q1= data["count"].quantile(0.25)
Q3= data["count"].quantile(0.75)
IQR= Q3-Q1

lower_limit= Q1 - 1.5*IQR
upper_limit= Q3 + 1.5*IQR

data[data["count"]>upper_limit]["count"].count()

"""* Upon observing the data, it is evident that the data is right-skewed and contains outliers.
* There are 300 outliers where the values exceed the upper limit.
* The mean value is 191.
* The minimum value is 1, and the maximum value is 977.

**2. Categorical variables:**
"""

labels= data["season"].value_counts().index
labels

# Holiday
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.countplot(data=data, x="holiday")
plt.title("Distribution of Bike Rides on Holidays vs. Non-Holidays ", color="red", fontsize=10)

plt.subplot(1,2,2)
sns.countplot(data=data, x="workingday")
plt.title("Distribution of Bike Rides on Weekdays vs. Weekends", color="red", fontsize=10)

plt.show()

# percentage of bike rides
rides_h=(data.groupby("holiday")["count"].sum())/data["count"].sum()*100
rides_h

# percentage of bike rides
rides_w= data.groupby("workingday")["count"].sum()/data["count"].sum()*100
rides_w

"""Here, we observe the distribution of bike rides during holidays and working days.

* The majority of bike rides, 97.22% of the total, are observed on non-holidays, whereas only 2.77% of bike rides occur on holidays.

* The majority of bike rides, accounting for 68.6% of the total, are observed on working days. Meanwhile, 31% of bike rides are observed on holidays.
"""

season=data.groupby("season")["count"].sum()
size=np.array(season.values)
labels=np.array(season.index)

weather=data.groupby("weather")["count"].sum()
size_w=np.array(weather.values)
labels_w=np.array(weather.index)

# pie chart of season
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.pie(season.values, labels=season.index,  autopct='%1.1f%%', startangle=90,  explode=(0,0,0,0))
plt.xlabel("Season")
plt.title("Distribution of Bike Rides by Season", color="red", fontsize=10)

#pie chart of weather
plt.subplot(1,2,2)
plt.pie(size_w, labels=labels_w,  autopct='%1.1f%%', startangle=120,  explode=(0,0,0,0.2))
plt.title("Distribution of Bike Rides by Weather Conditions", color="red", fontsize=10)
plt.xlabel("Weather")
plt.show()

"""**Season:**
* From the pie chart, we observe that:
1. Season 3 has the highest number of bike riders, accounting for 30.7% of the total bike rides.
2. Season 2 follows closely with 28.2% of the total bike rides.
3. Season 4 and Season 1 account for 26.1% and 15% of the total bike rides, respectively.

**weather:**
1. Weather type 1 has the majority of bike rides, accounting for 70.8% of the total, followed by weather types 2 and 3, which make up 24.3% and 4.9% of the total bike rides.

2. Weather type 4 has 0% of bike rides

**Outlier detation and deletion:**

Converting categorical variables from datatype object to the appropriate categorical type.
"""

data["season"]=data["season"].astype("object")
data["holiday"]=data["holiday"].astype("object")
data["workingday"]=data["workingday"].astype("object")
data["weather"]=data["weather"].astype("object")

data.info()

df_num=data.select_dtypes(include= np.number)

df_num.columns

df_cat=data.select_dtypes(include="object")
df_cat.columns

df_cat.shape

"""**Outlier treatment:**"""

Q1=df_num.quantile(0.25)

Q3=df_num.quantile(0.75)

IQR = Q3-Q1

IQR

# Outlier filter:
df_iqr= data[~((df_num<(Q1 - 1.5 * IQR)) | (df_num > ( Q3 + 1.5 * IQR))).any(axis=1)]

df_iqr.shape

"""We can observe that initially, we had 1088 rows in the dataframe. After filtering out outliers, we now have 9518 rows."""

plt.figure(figsize=(12,4))

plt.subplot(1,3,1)
sns.boxplot((df_iqr["temp"]))

plt.subplot(1,3,2)
sns.boxplot(df_iqr["atemp"])

plt.subplot(1,3,3)
sns.boxplot(df_iqr["humidity"])

plt.show()

plt.figure(figsize=(16,12))

plt.subplot(3,4,1)
sns.boxplot(df_iqr["windspeed"])

plt.subplot(3,4,2)
sns.boxplot(df_iqr["casual"])

plt.subplot(3,4,3)
sns.boxplot(df_iqr["registered"])

plt.subplot(3,4,4)
sns.boxplot(df_iqr["count"])

plt.show()

"""# <font color='red'>2. Try establishing a Relationship between the Dependent and Independent Variables.</font>

<font color='blue'>**1. Numerical vs numerical variables:**</font>
"""

df_iqr[["temp","atemp","humidity","windspeed","casual","registered","count"]].corr()

"""Correlation between temp and count

* H0: No correlation
* Ha: There is correlation
"""

from scipy.stats import spearmanr
spearmanr(df_iqr["temp"],df_iqr["casual"])

spearmanr(df_iqr["temp"],df_iqr["registered"])

spearmanr(df_iqr["temp"],df_iqr["count"])

plt.figure(figsize=(8,6))

sns.heatmap(df_iqr[["temp","humidity","windspeed","casual","registered"]].corr(method = 'spearman'), annot=True, vmax = .6, linewidths=0.01, square=True, cmap="YlGnBu")
plt.title("Correlation Between Variables", color="red", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""**Observation:**

The correlations between temperature and casual, registered, and all riders are as follows:
1. The correlation between temperature and casual riders is 0.53.
2. The correlation between temperature and registered riders is 0.29.
It can be observed that temperature and casual riders have a moderately strong positive correlation.

Wind speed has the same correlation with both casual and registered rides, which is 0.13. This indicates that wind speed and bike rides have a weak or no relationship.

The correlations between humidity and casual, registered, and all bike riders are as follows:
1. The correlation between humidity and casual riders is -0.33.
2. The correlation between humidity and registered riders is -0.30.
It can be observed that humidity has a negative correlation with both casual and registered bike riders.
"""

df_iqr.sample()

"""# <font color='red'>3. Check if there any significant difference between the no. of bike rides on Weekdays and Weekends?</font>"""

df_iqr["workingday"].value_counts()

df_iqr.groupby("workingday")["count"].describe()

df_workingday=df_iqr[["workingday","count"]]
df_workingday.sample().info()

sns.histplot(df_workingday["count"])

"""Transforming right skewed data to normali ditributed data using boxcox."""

from scipy.stats import boxcox
df_workingday["count"], best_lambda= boxcox(df_workingday["count"])

df_weekday=df_workingday[df_workingday["workingday"]==1]["count"]
df_weekend=df_workingday[df_workingday["workingday"]==0]["count"]

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
sns.histplot(df_weekday, kde=True)
plt.title("Distribution of Bike Rides on Weekdays", color="red", fontsize=10)

plt.subplot(1,2,2)
sns.histplot(df_weekend, kde=True)
plt.title("Distribution of Bike Rides on Weekends", color="red", fontsize=10)

plt.show()

"""**Null Hypothesis (H0) and Alternate Hypothesis (H1)**
*   H0: There is no significant difference between average bike rides on weekdays and weekends.
*   H1\: There is a significant difference between average bike rides on weekdays and weekends.

Here we can observe that the data approximately follows a Gaussian (normal) distribution, and the dataset is large. Therefore, we can apply a two-sample t-test in this case.
"""

from scipy.stats import ttest_ind

t_stat, p_val= ttest_ind(df_weekday, df_weekend, alternative="two-sided")
t_stat, p_val

"""* Significance level (alpha): 5% (0.05)
* Test statistic: 10.00135368319239
* p-value: 1.9618398183131075e-23
The p-value is close to zero and less than the significance level (alpha), therefore we reject the null hypothesis (H0).

**Conclusion:** There is a significant difference in the average bike rides between weekdays and weekends.

* H0: There is no significant difference between average bike rides on weekdays and weekends.
* H1: Average bike rides on weekdays are greater than average bike rides on
weekends.
"""

t_stat, p_val= ttest_ind(df_weekday, df_weekend, alternative="greater")
t_stat, p_val

"""* Significance level (alpha): 5% (0.05)
* Test statistic: 10.00135368319239
* P-value: 9.809199091565538e-24
The p-value is close to zero and less than the significance level (alpha), we can reject the null hypothesis (H0).

Conclusion: The average bike rides on weekdays are greater than the average bike rides on weekends.

# <font color='red'>4. Check if the demand of bicycles on rent is the same for different Weather conditions?</font>
"""

df_iqr.groupby("weather")["count"].describe()

"""**weather:**
1. Clear, Few clouds, partly cloudy
2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain +
Scattered clouds
4. Heavy Rain + Ice Pellets + Thunderstorm + Mist, Snow + Fog
"""

sns.boxplot(x="weather", y="count", data=df_iqr)

"""H0: All weather conditions have the same mean of bike rides.

H1: At least one of the weather conditions has a different mean of bike rides.
"""

df_weather=df_iqr[["weather","count"]]

sns.histplot(df_weather["count"])

"""**Check assumptions of the test.**"""

weather_1=df_weather[df_weather["weather"]==1]["count"]
weather_2=df_weather[df_weather["weather"]==2]["count"]
weather_3=df_weather[df_weather["weather"]==3]["count"]
weather_4=df_weather[df_weather["weather"]==4]["count"]

"""i. **Normality Test**

* Using QQ Plot to Check Gaussian Distribution:
The QQ plot (Quantile-Quantile plot) is used to assess whether the data follows a Gaussian distribution.
* Inability to Use Shapiro-Wilk Test Due to Large Data Size:
The Shapiro-Wilk test, typically recommended for sample sizes of 50-200, cannot be used effectively for large datasets.
"""

# QQPlot
import statsmodels.api as sm
import matplotlib.pyplot as plt

sm.qqplot(df_weather["count"], line="s")
plt.show()

df_weather["count"].skew()

df_weather["count"].kurt()

"""**Observation:**
* We can see that the variable count does not follow a normal distribution. Therefore, to compare the medians of independent groups (category weather), will use *the* Kruskal-Wallis test.
* We can see that the variable 'count' has right skewness (0.8923415130851888).
* Positive kurtosis (0.11828183897731259) suggests a distribution with heavy tails, indicating the presence of outliers.

**ii. Equality Variance**: levene Test
* H0: Variances are equal accross the groups.
* H1: Variances significantly different across the groups.
"""

from scipy.stats import levene
levene_stat, p_val=levene(weather_1, weather_2, weather_3, weather_4)
levene_stat, p_val

"""* alpha= 0.05
* pval= 1.1274167026429413e-26
**Conclusion:**

 * p-value (1.1274167026429413e-26) is very small and  less than the significance level (alpha = 0.05), we reject the null hypothesis (Ho). Therefore,The variances are significantly different across the groups.

**Null Hypothesis (H0) and Alternate Hypothesis (H1)**
* H0: There is no statistically significant difference in the medians of the groups.
* H1: There is a statistically significant difference in the medians of at least two groups.
"""

from scipy.stats import kruskal
stat, p_value= kruskal(weather_1, weather_2, weather_3, weather_4)
stat, p_value

"""**Obsevation:**
* alpha=5% (0.05)
* p value: 5.738374025114387e-25
* Conclusion: Since the p-value (5.738374025114387e-25) is very small and less than alpha, we reject the null hypothesis (Ho).
we can conclude that there is a statistically significant difference in the medians of at least two groups.

# <font color='red'> 5. Check if the demand of bicycles on rent is the same for different Seasons?</font>

**Seasons:**
* 1: spring, 2: summer, 3: fall, 4: winter
"""

df_iqr.groupby("season")["count"].describe()

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
sns.barplot(x="season", y="count", data=df_iqr)

plt.subplot(1,2,2)
sns.boxplot(x="season", y="count", data=df_iqr)

"""**Null Hypothesis and Alternate Hypothesis:**
* H0: The mean of bike rentals is the same across all seasons.
* H1: The mean of bike rentals varies across different seasons.
"""

from statsmodels.graphics.gofplots import qqplot
plt.figure(figsize=(8,4))
qqplot(df_iqr["count"], line="s")
plt.show()

df_iqr["count"].skew()

df_iqr["count"].kurt()

"""**Observtion:**
* We can observe from the qqplot that our data does not follow a Gaussian distribution.
* We can see that the variable 'count' has right skewness (0.8923415130851888).
* Positive kurtosis (0.11828183897731259) suggests a distribution with heavy tails, indicating the presence of outliers.

**ii. Equality Variance**
"""

season_1=df_iqr[df_iqr["season"]==1]
season_2=df_iqr[df_iqr["season"]==2]
season_3=df_iqr[df_iqr["season"]==3]
season_4=df_iqr[df_iqr["season"]==4]

"""**levene Test**
* H0: Variances are equal accross the groups.
* H1: Variances are significantly different across the groups.
"""

levene_stat, p_val= levene(season_1["count"], season_2["count"], season_3["count"], season_4["count"])
levene_stat, p_val

"""* Alpha = 0.05
* P-value = 6.687186315723853e-87
* Since the p-value is very small (much less than alpha), we reject the null hypothesis (Ho).
**Conclusion:** The variances significantly differ across the groups.

we obsereved that the data does not follow a normal distribution and the sample size is large, we will use the Kruskal-Wallis test.
"""

stats, p_val= kruskal(season_1["count"], season_2["count"],season_3["count"],season_4["count"])
stats, p_val

"""**Observation:**
* Alpha = 0.05
* P-value = 9.092946705054743e-93
* Since the p-value is much less than alpha, we reject the null hypothesis (H0).
* *Conclusion:* At least one group has a different median. Therefore, the medians of bike rentals differ across all seasons.

# <font color='red'>6. Check if the Weather conditions are significantly different during different Seasons?</font>

**Seasons:** 1: spring, 2: summer, 3: fall,  4:winter.      

**Weather:**
1. Clear, Few clouds, partly cloudy
2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain +
Scattered clouds
4. Heavy Rain + Ice Pellets + Thunderstorm + Mist, Snow + Fog
"""

# Cross table for weather vs season
cross_tab=pd.crosstab(df_iqr["season"],df_iqr["weather"], margins=True)
# Normalized cross_tab
cross_tab_norm=cross_tab/cross_tab.loc["All", "All"]
cross_tab_norm*100

plt.figure(figsize=(8,4))

pd.crosstab(df_iqr["season"],df_iqr["weather"]).plot(kind="bar", stacked=True)
plt.title("Weather Distribution Across All Seasons", color="red", fontsize=12)
plt.legend(loc="upper right")
plt.show()

"""**Null Hypothesis and Alternate Hypothesis:**
* H0: Season does not impact the weather.
* H1: Season impact the weather.

**Distribution:**
Chi-square distribution.
"""

from scipy.stats import chi2_contingency

chi_stat, p_value, df, exp_freq = chi2_contingency(pd.crosstab(df_iqr["season"],df_iqr["weather"]))
print("Chi_stats:",chi_stat)
print("P Value:", p_value)
print("Df:", df)
print("Exp_freq:",exp_freq)

"""* significance level: 5% (0.05)
* P value: 1.0976664201931232e-07
* *Conclusion:* Since the p-value (1.0976664201931232e-07) is less than the significance level (alpha = 0.05), we reject the null hypothesis (H0). we can conclude that season does impact weather.

**Observation:**
We observe from the plot and cross-table that weather 1 is the dominant weather pattern across all seasons, followed by weather 2 and weather 3.
* In Season 1 (Spring), weather 1 (mostly clear) accounted for 16.8%, followed by 7.2% for weather 2 (partially cloudy), and 2% for weather 3 (light snow, light rain, and thunderstorm). Only Season 1 had weather 4 (heavy rain + ice pellets + thunderstorm + mist, snow + fog) with a very low percentage of 0.01%.

* Season 2 had 15.5% for weather 1 (mostly clear), followed by 6.5% for weather 2 (partially cloudy), and 2.2% for weather 3 (light snow, light rain, and thunderstorm).

* Season 3 had 16.8% for weather 1 (mostly clear), followed by 5.4% for weather 2 (partially cloudy), and 1.8% for weather 3 (light snow, light rain, and thunderstorm).

* Season 4 had 15.9% for weather 1 (mostly clear), followed by 8% for weather 2 (partially cloudy), and 2.2% for weather 3 (light snow, light rain, and thunderstorm).

# **<font color='red'> Insights:</font>**

**Holiday vs. Working Days:**
*	The majority of bike rides, 97.22%, occur on No Holidays, indicating that weekdays are more popular for bike usage.
*	Holidays account for only 2.77% of the total bike rides, very less bike usage on these days.

**Seasonal:**
*	Season 3 sees the highest bike rides at 30.7%, followed closely by Season 2 with 28.2%.
*	Season 4 and Season 1 have slightly lower percentages at 26.1% and 15%

**Weather Conditions:**
*	Weather type 1 (Mostly Clear) dominates bike rides, constituting 70.8% of the total.
*	Weather types 2 (Partly Cloudy) and 3 (Light Snow, Light Rain, and Thunderstorm) follow with 24.3% and 4.9%, respectively.
* As expected weather type 4 ('Heavy Rain + Ice Pellets + Thunderstorm + Mist, Snow + Fog') has 0% of bike rides

**Temperature and Bike Riders:**
*	Casual riders show a stronger positive correlation (0.53) with temperature compared to registered riders (0.29).
*	This suggests that casual riders, who are likely more influenced by weather conditions, tend to increase their usage as temperatures rise (winter to summer).

**Wind Speed and Humidity:**
* Both casual and registered riders have a weak positive correlation (0.13) with wind speed, indicating minimal or no impact on bike usage.
* Humidity negatively correlates with both casual (-0.33) and registered (-0.30) riders, suggesting that higher humidity levels decreases bike usage.

# **<font color='red'> Recommendations:</font>**

* As we know, workdays and non-workdays are the most influential factors in bike rides. We have observed that working days and non-holidays account for most of the bike rides. This time is the best for business planning. Accordingly, we can plan our inventory, supply chain, and quick customer services for a better customer experience. We can also adjust our prices for higher profitability during peak times. This also a best time to introduce new transportation-related services.

* Holidays and weekends see lower bike ride volumes. Advertising and offering discounts on rides can help improve business during these periods.

* The second most influential factor is weather; we have observed that 71% of bike rides occur on clear days, followed by partially cloudy and light rain days (24%). Weather forecasts are crucial for inventory planning and pricing strategies. We can adjust our prices based on weather conditions, offering minimal surcharges on clear days and discounts on partially cloudy or rainy days.

* We have also identified a strong correlation between temperature increases and casual riders. This suggests that clear seasons are the optimal time to convert casual bike riders into registered riders.

* Both casual (-0.33) and registered (-0.30) riders show a negative correlation with humidity, indicating that higher humidity levels decrease bike usage.
offering discounts or promotions during periods of high humidity to incentivize ridership.

* Bike rides are highly influenced by both workdays and holidays, as well as weather conditions. Therefore, monitoring weather conditions and planning business strategy are crucial. Since ridership increases during clear and pleasant days, providing weather information through appropriate advertisements and offering additional discounts via the service app during low business days can further improve business.
"""

